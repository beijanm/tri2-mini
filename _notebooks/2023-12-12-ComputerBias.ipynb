{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "toc: true\n",
    "comments: true\n",
    "layout: post\n",
    "title: Computing Bias\n",
    "description: Team teach about beneficial and harmful effects\n",
    "courses: { compsci: {week: 16} }\n",
    "type: hacks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Computing Bias\n",
    "A brief introduction to computing biases is that human biases are usually incorporated into algorithms or data. If this is confusing to understand, here is one example. When you are browsing Netflix and look at the different categories, you see that typically there are a bunch of Netflix exclusives being displayed more than non-exclusives. This is a form of computing bias as this would benefit Netflix, as the movie or show will never leave Netflix. So, if you get hooked on that show, then you will inevitably keep paying the Netflix subscription."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of Bias:**\n",
    "\n",
    "1. **Algorithmic Bias:**\n",
    "   - Computers follow instructions called algorithms. If these instructions are based on unfair data, the computer can make biased decisions. For example, it might unfairly predict things about people based on old data that has unfair opinions.\n",
    "\n",
    "2. **Data Bias:**\n",
    "   - The information computers learn from (data) can be unfair, too. If the data is one-sided or reflects old prejudices, the computer might learn and repeat those unfair ideas.\n",
    "\n",
    "**Examples of Computer Bias:**\n",
    "\n",
    "1. **Facial Recognition:**\n",
    "   - Computers that recognize faces might have trouble with people who have darker skin. This happens because they were trained mostly on lighter-skinned people. This can lead to mistakes, like thinking someone did a crime when they didn't.\n",
    "\n",
    "2. **Job Recruitment Algorithms:**\n",
    "   - Imagine a computer helping a company pick new employees. If the computer was taught using mostly resumes from men, it might think men are better for the job. This happened with Amazon, and they had to stop using the computer for hiring.\n",
    "\n",
    "**Mitigating Computer Bias:**\n",
    "\n",
    "1. **Diverse and Representative Data:**\n",
    "   - To make computers fair, we need to use information that shows a mix of different people. This helps the computer learn without picking up old unfair ideas.\n",
    "\n",
    "2. **Regular Audits and Assessments:**\n",
    "   - People need to check computers often to make sure they're not being unfair. If they find a problem, they can fix it to make the computer better.\n",
    "\n",
    "3. **Transparency and Explainability:**\n",
    "   - Computers should be easy to understand. If we know how they make decisions, we can fix them when they're wrong.\n",
    "\n",
    "4. **Diverse Development Teams:**\n",
    "   - The people who make computers should come from different backgrounds. This way, they can catch unfair things that others might miss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***POPCORN HACK 1***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoanApprovalAlgorithm:\n",
    "    def __init__(self, income, credit_score, years_of_employment, zip_code):\n",
    "        self.income = income\n",
    "        self.credit_score = credit_score\n",
    "        self.years_of_employment = years_of_employment\n",
    "        self.zip_code = zip_code\n",
    "\n",
    "    def approve_loan(self):\n",
    "        # Initial biased decision-making process\n",
    "        if self.income > 50000 and self.credit_score > 700 and self.years_of_employment > 2:\n",
    "            if self.zip_code not in [\"high-income-zip-1\", \"high-income-zip-2\"]:\n",
    "                return \"Loan Approved\"\n",
    "        return \"Loan Denied\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Answer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairLoanApprovalAlgorithm:\n",
    "    def __init__(self, income, credit_score, years_of_employment, zip_code):\n",
    "        self.income = income\n",
    "        self.credit_score = credit_score\n",
    "        self.years_of_employment = years_of_employment\n",
    "        self.zip_code = zip_code\n",
    "\n",
    "    def approve_loan(self):\n",
    "        # Revised decision-making process to mitigate bias\n",
    "        if self.income > 50000 and self.credit_score > 700 and self.years_of_employment > 2:\n",
    "            return \"Loan Approved\"\n",
    "        return \"Loan Denied\"\n",
    "\n",
    "# Example Usage\n",
    "applicant1 = FairLoanApprovalAlgorithm(60000, 750, 3, \"high-income-zip-1\")\n",
    "result1 = applicant1.approve_loan()\n",
    "print(f\"Applicant 1: {result1}\")\n",
    "\n",
    "applicant2 = FairLoanApprovalAlgorithm(45000, 720, 2, \"low-income-zip-1\")\n",
    "result2 = applicant2.approve_loan()\n",
    "print(f\"Applicant 2: {result2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE OUTPUT SHOULD BE SOMETHING LIKE\n",
    "\n",
    "Applicant 1: Loan Approved\n",
    "Applicant 2: Loan Denied\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
